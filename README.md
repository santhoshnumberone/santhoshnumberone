# 👋 Hi, I'm Santhosh — Local-First AI Builder | LLM Engineer | Product Thinker

---

## 🧩 The Pain  
_Almost every dev wants to experiment with LLMs — but experimentation means trial and error.
And trial and error comes at a cost._

_With cloud APIs, those costs compound fast — every prompt, every test run, every misstep eats into time and money.
Latency, usage caps, and vendor lock-in only add more friction._

_Whether you're a solo builder, startup, or enterprise — **cost sensitivity is real**.  
And if you're working on a tight setup (like I was, with 8GB RAM and no GPU), it's not just inconvenient — it's a hard blocker to progress._

---

## 💥 The Breaking Point  
Anyone building on an 8GB MacBook is bound to hit a wall fast.  
Every prototype turns into a budgeting decision.

And for those of us who care about privacy or need offline reliability, cloud APIs aren’t just inconvenient — they’re a blocker.  
For learners like me, it wasn’t just about building — it was about *getting started at all*.

---

## 🛠️ The Build

_Harvey Specter once said:_  
> “When you're backed against the wall, break the goddamn thing down.”

So I did.
I flipped the stack — **vocal to local** — and started building fully local, open-source LLM tools using:
- 🔗 **LangChain** (retrievers, prompts, agents, memory)
- 🧠 **FAISS** for vector search
- 🤗 **Hugging Face Transformers + SentenceTransformers**
- 🧩 **llama.cpp** with 4-bit GGUF models (Mistral, Zephyr)  
- 💡 Custom prompt logic, fallback flows, and user-driven CLI UX

My focus: building lean, reproducible, zero-API workflows — ideal for devs, tinkerers, and anyone building in bandwidth or cost-constrained environments.

---

## 🔎 The Insight  
Local-first LLMs give you full control over reliability, iteration speed, and customization.  
They shift AI from **a rented service** to **a tool you actually own** — and most importantly,  
they **bring the cost down to zero**.

That’s what excites me.

---

## 📊 The Proof  
| Project | Purpose |
|--------|---------|
| `llm-power-search` | ✅ Local RAG pipeline that answers legal questions about open-source licenses using LangChain + FAISS + llama.cpp |
| `inference-benchmark` *(Medium-linked)* | 📈 Performance comparison of 4-bit models on Mac M1 using llama.cpp, including speed vs GPU benchmarks |

More tools and ideas in progress — and I’m just getting started. 😄

---

## 🧠 Tech Stack

- 🔗 LangChain · FAISS · SentenceTransformers  
- 🧩 llama.cpp · Hugging Face · GGUF 4-bit models  
- ⚙️ Python · CLI tooling · Local inference pipelines  
- 🧪 PyTorch · TensorFlow (CV/ML background)  
- 🧰 C++ (Gtkmm), Python (PyQt/OpenCV) for earlier UI systems

---

## 🚀 I’m Open To:
- ✅ Remote roles in **LLM prototyping** or **AI devtools**  
- ✅ **AI Product Management** roles focused on user-first GenAI tools  
- ✅ OSS / SaaS collabs with a focus on usability, cost-efficiency, and impact  

📩 <santhoshnumber1@gmail.com>  
🔗 [LinkedIn →](https://www.linkedin.com/in/santhosh-electraanu/)

---

## 🎓 Learning & Certifications

- [✔️ Prompt Engineering for ChatGPT (Coursera)](https://coursera.org/share/7197a7bd0ae717ecced1ed917a54f3e8)  
- [✔️ Trustworthy Generative AI (Vanderbilt)](https://coursera.org/share/6c5944df9f15f37a9082aebf20d7ca6a)  
- [✔️ ChatGPT Advanced Data Analysis (Vanderbilt)](https://coursera.org/share/8ae368d556e85dcf809a107b823d212d) 
- 🧠 LangChain Dev Course (DeepLearning.AI)  
- 🔬 ChatGPT Prompt Engineering for Developers (OpenAI)

---

## 🔁 My Journey So Far

### 📍 Where I Started  
I began my career as a Computer Vision developer — building tools that combined low-level image processing with product intuition.

Projects included:
- 🥔 **Size & color–based potato sorting system** — image processing algorithm deployed via Google Cloud Functions
- 🧪 **Custom designed CNN trained from scratch** on a local machine for spliced image forgery detection (600+ epochs)
- 👁️ **Early glaucoma detection prototype** — built on Raspberry Pi with OpenCV + VR headset integration
- 🚗 **Real-time vehicle flow analysis** — 24-hour video inference across lanes on AWS servers using YOLO
- 🧰 **Internal OpenCV tool replication** — led a team replicating a core analytics tool for reuse
- 🧑‍💻 **Full UI/UX design** for embedded systems — owned v1 + v2 flow for industrial machine vision tool

---

### 🔄 Where I Am Now  
From the start, I've owned not just features — but the full flow: 
`problem` → `interface` → `model` → `deployment`.
That mindset now drives my transition into:
- ✅ **LLM prototyping**
- ✅ **Offline AI tooling**
- ✅ **End-to-end product thinking**

What began as an **offline learning constraint** turned out to be a **blessing** — forcing me to focus on **privacy**, **full ownership**, and **infinite iteration** where imagination was the only limit (and system RAM the only bottleneck). 

That journey led to **zero-cost**, local-first tools that work for **solo devs**, **startups**, and **eventually even cost-sensitive enterprises**.

It’s no longer just about building features — I’m evolving into a product manager who takes full ownership, end to end.

---

> 🧪 From a young boy who believed that — unlike most things in life — **code usually does exactly what you want**...  
to early repos here that might not mean much to others,  
but marked real milestones for me.  
And soon: tools that I hope will matter — not just to me, but to many of us building with constraints, creativity, and purpose.

